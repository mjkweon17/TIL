### 용어
- t3
    - 버스터블 성능(burstable performace) 인스턴스 유형 중 하나를 나타냄
    - 비용 효율성과 유연성이 뛰어나며, 일반적으로 변동성이 크지 않은 워크로드에 적합함
    - CPU 크레딧을 활용하여 평균 CPU 사용량이 낮은 경우에도 일정 기간동안 높은 CPU 성능을 제공할 수 있음
    - 특징
        - CPU 크레딧: CPU 크레딧 메커니즘에 기반하여 작동함. 인스턴스는 시간당 일정량의 CPU 크레딧을 축적하며, 이 크레딧은 필요에 따라 사용됨. 인스턴스가 유휴 상태일 때는 크레딧을 축적하고, 더 많은 컴퓨팅 파워가 필요할 때 이 크레딧을 사용하여 성능을 일시적으로 증가시킬 수 있음
        - 경제성: 비용 효율적. 일반적인 사용 패턴에서는 더 낮은 비용으로 충분한 성능을 제공할 수 있어, 개발 환경, 테스트 환경, 소규모 애플리케이션 또는 간헐적인 워크로드에 적합함
        - 유연성: 다양한 사이즈로 제공됨. 사용자는 워크로드 요구 사항에 맞게 인스턴스를 선택할 수 있음. 
        - 자동 크레딧 균형: AWS는 CPU 크레딧 균형을 자동으로 관리하여, CPU 크레딧이 고갈되지 않도록 함. 이를 통해 인스턴스가 일정 기간 동안 높은 CPU 사용량을 유지해야 할 경우에도 성능이 유지될 수 있도록 노움.

- 애플리케이션의 규모
    - 일반적으로 사용자 수, 트래픽 양, 데이터 처리 요구 사항, 인프라의 복잡성 등을 기준으로 판단됨
    - 중소 규모 애플리케이션
        - 사용자 수: 일반적으로 수백에서 수천 명의 동시 사용자를 지원함. 애플리케이션이 감당할 수 있는 동시 요청의 수와 직접적으로 관련이 있음
        - 트래픽 양: 페이지 뷰, API 호출 수, 사용자 요청의 복잡성 등에 따라 다를 수 있음. 일반적으로 하루에 수만에서 수백만 건의 요청을 처리할 수 있어야 함.
        - 데이터 처리 요구 사항: 데이터베이스 크기는 보통 수 GB에서 수십 GB 정도이며, 간단한 쿼리에서부터 중간 정도의 복잡성을 가진 데이터 처리 작업을 수행할 수 있어야 함.
        - 인프라의 복잡성: 일반적으로 몇 대의 서버(또는 클라우드 기반 인스턴스)와 기본적인 스케일링, 백업, 보안 조치를 포함함. 고가용성과 재해 복구를 위한 기본적인 설정을 포함할 수 있으나, 대규모 시스템에 비해 상대적으로 단순함. 
        - 개발 및 운영 팀의 규모: 일반적으로 소규모에서 중규모의 개발 및 운영 팀(몇 명에서 수십 명)에 의해 관리됨
        - 예시: 스타트업의 초기 제품, 소규모 e-커머스 사이트, 내부 관리 시스템, 중소기업의 고객 관리 시스템 등

## Pricing Calculator

### RDS for PostgreSQL
- DB 인스턴스 수: 실행할 데이터베이스 서버의 수
    - 고려사항
        - 트래픽과 처리량: 애플리케이션의 예상 트래픽과 데이터 처리량이 중요한 고려 사항. 높은 트래픽과 데이터 처리가 예상되는 경우, 더 많은 인스턴스가 필요할 수 있음.
        - 가용성과 내구성: 고가용성을 위해서는 여러 인스턴스를 다른 가용 영역에 배포해야 함. RDS는 다중 AZ 배포를 지원하여, 하나의 AZ에 장애가 발생해도 다른 AZ의 인스턴스로 자동 장애 전환을 제공함
        - 성능 요구 사항: 애플리케이션의 성능 요구 사항에 따라 다른 인스턴스 유형 또는 추가 인스턴스가 필요할 수 있음. 일부 작업은 높은 CPU, 메모리 또는 I/O 성능을 요구할 수 있음
        - 비용: 인스턴스 수를 늘리면 비용이 증가함. 비용과 성능 사이의 균형을 찾는 것이 중요
    - 단일 인스턴스 배포: 간단한 애플리케이션 또는 개발/테스트 환경의 경우, 하나의 DB 인스턴스로 시작할 수 있음
    - 다중 AZ 배포: 프로덕션 환경에서는 높은 가용성을 위해 다중 AZ 배포를 고려해야 함. 이 경우 최소 2개의 인스턴스가 필요하며, 이들은 서로 다른 가용 영역에 배치됨
- 다중 AZ 배포
    - 고가용성과 내구성을 위해 AWS에서 제공하는 기능
    - AZ는 데이터 센터의 물리적인 위치를 나타내며, 각각은 서로 다른 지리적 위치에 존재함.
    - 다중 AZ 배포를 사용하면, 데이터베이스 인스턴스를 여러 가용 영역에 걸쳐 복제하여 운영할 수 있음. 이는 데이터베이스의 가용성과 내구성을 크게 향상시킴.
    - 주요 특징과 이점
        - 고가용성: 하나의 AZ에 장애가 발생했을 때, 자동으로 다른 AZ에 있는 대기 인스턴스로 트래픽을 전환함. 이는 응용 프로그램의 중단 시간을 최소화하여 연속적인 서비스 가용성을 보장함
        - 자동 장애 전환: AWS는 장애 감지와 장애 전환 프로세스를 자동으로 관리함. 데이터베이스 인스턴스에 문제가 발생하면, AWS는 대기 인스턴스를 자동으로 주 인스턴스로 승격시켜 서비스 중단을 최소화함
        - 데이터 내구성: 데이터를 여러 위치에 복제함으로써 데이터 손실의 위험을 줄임. 하나의 AZ에 문제가 발생해도, 다른 AZ에 있는 데이터는 안전하게 보호됨
        - 유지 관리와 백업: 주기적인 유지 관리 작업과 백업을 위해 대기 인서턴스를 사용하여, 이러한 작업이 주 인스턴스의 성능에 미치는 영향을 최소화함
    - 다중 AZ 배포는 특히 미션 크리티컬한 애플리케이션에 적합함.
        - 미션 크리티컬 시스템: 사업이나 조직의 생존에 필수적인 시스템. 미션 크리티컬 시스템이 실패되거나 간섭을 받으면 사업 운영에 상당한 영향을 받음.
    - 다중 AZ 배포를 설정할 떄 인스턴스 수
        - 1개여도 됨. 다중 AZ 배포의 핵심 개념은 단일 인스턴스가 아닌, 하나의 '프라이머리' 인스턴스와 하나 이상의 '스탠바이' 인스턴스 간의 관계에 초점을 맞추는 것. 여기서 중요한 점은 사용자가 직접 관리하는 인스턴스의 수가 아니라, AWS가 자동으로 관리하는 스탠바이 인스턴스의 존재.
- 인스턴스 유형
    - 범용 인스턴스(General Purpose)
        - t3.micro 또는 t3.small: AWS의 범용 인스턴스 유형 중에서 가장 작고 비용 효율적인 옵션. 초창기 앱 개발과 테스트 단계에 적합하며, 필요에 따라 쉽게 확장할 수 있음. CPU 크레딧을 사용하여 일정 기간 동안 성능을 향상시킬 수 있는 버스트 기능을 제공함
    - 메모리 최적화 인스턴스
        - 초기 단계에는 메모리 최적화 인스턴스가 필요하지 않을 수 있음. 그러나 데이터베이스가 메모리 집약적 작업을 수행해야 하는 경우에는 r5.large와 같은 메모리 최적화 인스턴스를 고려할 수 있음. 하지만, 이는 비용이 많이 들 수 있음
    - 고려사항
        - 비용: 앱의 초기 단계에서는 비용을 가능한 한 낮게 유지하는 것이 주용. t3.micro 또는 t3.small 같은 범용 인스턴스는 낮은 비용으로 시작할 수 있는 좋은 옵션
        - 확장성: 사용자 기반과 데이터 요구사항이 증가함에 따라, 선택한 인스턴스 유형이 쉽게 확장 가능한지 확인해야 함.
        - 성능: 앱의 성장에 따라 성능을 모니터링하고 필요에 따라 인스턴스를 업그레이드하는 것이 중요함.
- 사용량 고려 요소
    - Value
        - 데이터 크기: 데이터베이스에 저장되는 정보의 양
        - 사용자 프로필, 트랜잭션 기록, 로그 파일 등 다양한 데이터 유형을 포함할 수 있음
        - 쿼리의 복잡성과 빈도: 데이터베이스에 대한 쿼리가 얼마나 복잡하고 자주 발생하는지. 복잡하고 자주 발생하는 쿼리는 더 많은 컴퓨팅 리소스를 소모함.
        - 인덱싱 전략: 데이터 검색 속도를 높이기 위해 인덱스를 어떻게 구성하느냐도 중요. 효율적인 인덱싱은 성능을 크게 향상시킬 수 있지만, 공간을 추가로 사용함
    - Unit
        - 스토리지 용량: 데이터베이스에 할당된 저장 공간의 양. GB 또는 TB로 측정됨.
        - 컴퓨팅 리소스: CPU와 메모리 용량. 데이터베이스의 처리 능력을 결정함.
        - IOPS(초당 입출력 연산 수): 데이터베이스의 입출력 성능을 나타냄. 고성능의 IOPS는 높은 데이터 처리량을 지원함.
    - 배포 옵션
        - 단일 인스턴스 vs 다중 AZ 배포: 단일 인스턴스는 비용 효율적이지만, 다중 AZ는 높은 가용성과 내구성을 제공함
        - 서버리스 데이터베이스: 사용량에 따라 자동으로 스케일링되는 서버리스 옵션은 관리부잠을 줄여줌. Aurora Serveless가 이에 해당함.
        - 리전과 가용 영역: 데이터베이스를 호스팅할 지리적 위치는 성능과 규정 준수에 영향을 줌
    - 요금 모델
        - 온디맨드 요금제: 사용한 만큼만 비용을 지불하는 모델. 초기 비용 없이 시작할 수 있으나, 장기적으로는 비용이 더 높을 수 있음
        - 예약 인스턴스: 미리 일정 기간 동안 리소스를 예약하는 방식. 초기 투자가 필요하지만, 장지적으로는 온디맨드 요금제보다 저렴할 수 있음
        - 스토리지 비용과 전송 비용: 저장된 데이터의 양과 데이터를 전송하는 데 드는 비용도 고려해야 함
- 중소 규모 애플리케이션
    - 데이터베이스 인스턴스: db.t3.micro 또는 db.t3.small 인스턴스를 선택하여 비용을 절감하면서도 중소 규모 애플리케이션에 충분한 선ㅇ을을 제공
    - 스토리지 타입: 범용 SSD(GP2) 스토리지를 선택하여 균형 잡힌 성능과 비용을 제공함
    - 스토리지 용량: 초기 단계에서는 20GB 정도로 시작하여, 데이터 사용량을 모니터링하면서 필요에 따라 용량을 조정함

### EC2
- Auto Scaling
    - 애플리케이션의 요구 사항과 트래픽에 따라 EC2 인스턴스의 수를 자동으로 조절할 수 있음
    - 설정 방법: Auto Scaling그룹을 생성하고, 최소 및 최대 인스턴스 수를 설정함. 또한, 확장 정책을 정의하여 특정 조건(예: CPU 사용률, 네트워크 트래픽 등)에 따라 인스턴스를 자동으로 추가하거나 제거할 수 있음
    - 효과: 트래픽 증가 시 자동으로 인스턴스를 추가하여 부하를 처리하고, 트래픽 감소 시 인스턴스를 자동으로 줄여 비용을 절약할 수 있음
    - Pricing Calculator에서 직접적으로 Auto Scaling을 별도의 서비스로 설정하는 옵션은 없음. 대신, EC2 인스턴스의 수를 조정하여 예상 트래픽과 필요한 인스턴 수를 반영할 수 있음. 평균적으로 필요한 인스턴스 수를 추정하여 입력.
    - 추가 비용: 인스턴스 추가/제거 시 발생할 수 있는 데이터 전송 비용
- Auto Scaling과 Load Balancer의 결합 사용
    - Auto Scaling과 로드 밸런서를 함께 사용하면 애플리케이션의 확장성과 가용성을 크게 향상시킬 수 있음. Auto Scaling 그룹을 로드 밸런서에 등록하여, 인스턴스가 자동으로 추가되거나 제거될 때 로드 밸런서가 이를 감지하고 트래픽 분산 규칙을 자동으로 조정하도록 할 수 있음.
- 중소 규모 애플리케이션
    - 인스턴스 유형: t3.medium 인스턴스가 일반적으로 적합한 성능과 비용의 균형을 제공함. 
    - 초기 서비스의 경우 Auto Scaling을 고려하여 최소 인스턴스 수를 1로 설정하고, 트래픽 증가에 따라 자동으로 확장할 수 있도록 구성
    - 온디맨드 인스턴스: 비용을 절약하기 위해 예약 인스턴스나 스팟 인스턴스로 시작하는 대신, 온디맨드 인스턴스로 시작하여 사용량을 모니터링하고 필요에 따라 구매 옵션을 조정함


### Load Balancer
- 들어오는 네트워크 트래픽을 여러 EC2 인스턴스에 분산시켜 처리하는 역할을 함. 애플리케이션의 가용성과 내구성을 향상시킴.
- 유형:  ALB(Application Load balancer)는 HTTP/HTTPS 트래픽에 최적화됨. NLB(Network Load Balancer)는 TCP 트래픽에 최적화됨. ELB(Elastic Load Balancer)는 이전 세대의 로드 밸런서임.
- 설정 방법: 로드 밸런서를 생성하고, 대상 그룹에 EC2 인스턴스를 등록함. 그런 다음, 들어오는 트래픽을 로드 밸런서에 연결하고, 로드 밸런서가 트래픽을 등록된 인스턴스에 분산시키도록 설정함.
- 추가 비용: 시간당 요금, 처리된 데이터의 양에 따른 비용
- 적절한 로드 밸런서의 수
    - 애플리케이션의 아키텍처, 트래픽의 양, 가용성 요구 사항, 개해 복구 계획에 따라 달라짐.
    - 대부분의 경우 하나의 로드 밸런서가 초기 설정이나 중소 규모의 애플리케이션에 충분함. 클라우드 환경에서 로드 밸런서를 여러 개 사용하는 경우는 비교적 드뭄.
    - ELB 서비스는 고가용성을 자동으로 제공하며, 하나의 로드 밸런서 인스턴스가 여러 가용 영역에 걸쳐 트래픽을 분산할 수 있도록 설계됨
    - 하나의 로드 밸런서 사용 시 고려 사항
        - 단일 로드 밸런서로 충분: 대부분의 애플리케이션은 단일 로드 밸런서로 충분함. 관리가 간단함.
        - 비용 효율성: 추가 로드 밸런서를 배치하는 것보다 더 적은 비용으로 시작할 수 있으며, 필요에 따라 나중에 쉽게 확장할 수 있음
        제한된 확장성: 트래픽이 크게 증가하는 경우, 단일 로드 밸런서의 처리 용량이 한게에 도달할 수 있음. 그러나 현대의 클라우드 기반 로드 밸런서는 매우 높은 처리량을 지원하므로, 이는 드문 경우.
    - 여러 로드 밸런서가 필요한 경우
        - 다양한 트래픽 유형 처리: 애플리케이션에서 HTTP/HTTPS 트래픽과 TCP 트래픽을 모두 처리해야 하는 경우, 각각을 최적화하기 위해 별도의 로드 밸런서(ALB, NLB)를 사용할 수 있음.
        - 고급 라우팅 요구 사항: 특정 요구 사항에 따라 트래픽을 다르게 라우팅해야 할 때 여러 로드 밸런서를 사용할 수 있음. 예를 들어, 다른 지역이나 다른 VPC로 트래픽을 분산해야 하는 경우
        - 재해 복구 계획: 지리적으로 분산된 다중 리전 아키텍처를 사용하는 경우, 각 리전에 로드 밸런서를 배치하여 재해 발생 시 트래픽을 다른 리전으로 자동 전환할 수 있음
        - 로드 밸런서가 2개일 때: 다양한 트래픽 유형(예: 웹 트래픽과 API 트래픽)을 분리하거나, 다른 리스너 규칙을 적용하기 위해 두 개의 로드 밸런서를 사용할 수 있음.
        - 로드 밸런서가 3개 이상일 때
            - 고도의 분리 및 맞춤화: 매우 특정한 요구 사항이나 복잡한 아키텍쳐를 가진 대규모 애플리케이션에서 여러 로드 밸런서를 사용할 수 있음. 예: 다양한 지리적 위치에 서비스를 제공하거나 특정 애플리케이션 계층(웹, 애플리케이션, 데이터베이스)을 위해 별도의 로드 밸런서를 구성할 수 있음
- LCU(Load Balancer Capacity Unit)
    - ELB의 사용량을 측정하는 단위
    - ALB, NLB, GLB의 비용을 계산할 때 사용됨
    - 로드 밸런서가 처리해야 하는 트래픽의 양, 연결 수, 새로운 연결의 생성 속도 및 규칙 평가 등 여러 요소를 종합적으로 고려하여 계산됨
    - LCU 산정 시 고려해야할 주요 요소
        - 새로운 연결/초: 애플리케이션의 피크 시간 동안 예상되는 새로운 연결의 생성 속도를 추정
        - 활성 연결 수: 한 시점에 로드 밸런서가 유지하고 있는 활성 연결의 총 수. 평균적으로 유지될 수를 추정. 웹 애플리케이션의 경우, 사용자의 세션 유지 시간도 고려해야 함.
        - 처리량(Gbps): 로드 밸런서를 통과하는 데이터의 양. 전송되는 데이터의 양을 GB 단위로 추정. 대용량 미디어 파일을 다루는 서비스의 경우 처리량이 중요한 고려 사항이 될 수 있음.
        - 규칙 평가: 로드 밸런서에 설정된 리스너 규칙의 수와 복잡성. 복잡한 라우팅 로직이나 조건이 많을수록 더 많은 LCU가 소모됨.
    - LCU를 적절하게 산정하는 방법
        - 모니터링과 예층: 애플리케이션의 트래픽 패턴을 모니터링하여 피크 시간대의 연결 수, 처리량, 규칙 평가 등을 분석함.
        - 성능 테스트: 가능하다면, 실제 트래픽을 모방한 성능 테스트를 통해 로드 밸런서의 LCU 소모량을 측정해서 실제 운영 환경에서의 LCU 요구사항을 더 정확하게 파악할 수 있음
- Pricing Calculator에 LCU 적용 방법
    - 기본 추정치 제공: 중소 규모 서비스의 경우, 초당 연결 수가 수십에서 수백 건, 활성 연결 수가 수백에서 수천 건 정도, 그리고 처리량이 GB 단위로 낮을 것으로 예상할 수 있음. 이러한 기본 정보를 바탕으로 초기 LCU 요구 사항을 추정함
    - LCU 계산기 활용: AWS 공식 문서나 서드파티 도구를 참고하여 보다 정확한 LCU 사용량을 계산할 수 있음.
    - 성장 예측 포함: 서비스 성장에 따른 LCU 사용량 증가를 예측하여 여유를 두고 계산함. 이는 미래의 확장성을 고려한 비용 계획에 도움이 됨.
    - 비용 최적화 고려: 초기 추정을 바탕으로 비용 최적화 전략을 수립함. 예를 들어, LCU 사용량이 예상보다 높아지는 경우, 애플리케이션 성능 최적화나 규칙 단순화를 통해 LCU 소모를 줄일 수 있음.
- 중소 규모 애플리케이션
    - 로드 밸런서 유형: ALB는 중소 규모의 웹 애플리케이션 및 API 트래픽을 처리하기에 적합함
    - 로드 밸런서 수: 단일 ALB로 시작하여, 애플리케이션의 가용성과 성능 요구사항을 충족시키면서 비용 최소화
    - LCU
        - 새로운 연결 초: 초당 20개의 새로운 연결. 대부분의 시간 동안 비교적 낮은 트래픽을 경험하지만, 피크 시간에는 사용량이 증가할 수 있음
        - 활성 연결 수: 평균 1000개의 동시 활성 연결. 동시에 많은 사용자가 서비스를 이용하지만, 전체 사용자 수는 대규모 서비스에 비해 제한적일 수 있음.
        - 처리량: 평균 5GB/시간의 데이터 처리량. 대량의 미디어 전송보다는 텍스트 시반의 컨텐츠나 가벼운 미디어 요소를 포함할 가능성이 높음.
        - 규칙 평가: 10개의 리스너 규칙. 간단한 URL 경로 기반 라우팅이나 호스트 기반 라우팅을 구현할 때 필요한 규칙의 수.
        - 각 LUC는 초당 새로운 연결 25개, 초당 활성 연결 3000개, LCU 당 1GB/h의 처리량, 또는 5개의 규칙 평가를 지원함
            - 20개의 새로운 연결은 1 LCU 미만을 사용. 1000개의 활성 연결은 약 0.33 LCU를 사용. 5GB/시간은 5 LCU를 사용. 10개의 리스너 규칙은 2 LCU를 사용. 초기 추정치는 처리량과 규칙 평가에 기반하여, 총 7 LCU 정도가 필요할 것으로 보임. 하지만, 실제 필요한 LCU는 AWS에서 제공하는 실시간 모니터링 도구를 통해 정확하게 측정해야 함. 

### ECR
- Elastic Container Registry
    - Docker 컨테이너 이미지를 쉽게 저장, 관리, 배포할 수 있는 완전 관리형 도커 컨테이너 레지스트리 서비스
    - 주요 기능과 장점
        - 간편한 컨테이너 이미지 관리
            - Docker 이미지와 OCI(Open Container Initiavtive) 이미지 포맷을 지원하며, 이미지를 쉽게 푸시, 풀 및 관리할 수 있는 환경을 제공함
        - 높은 확장성
            - 수백만 개의 컨테이너 이미지를 저장하고, 전 세계 어디서나 손쉽게 접근할 수 있음
        - 보안
            - 컨테이너 이미지를 전송하는 동안 및 저장 중에 데이터를 암호화함
            - IAM을 사용하여 레지스트리 접근 권한을 세밀하게 제어할 수 있음
            - 이미지 스캔 기능을 통해 알려진 취약점을 자동으로 발견할 수 있음
        - 통합 및 자동화
            - ECS, EKS, Lambda 등 AWS의 다른 서비스와 원활하게 통합됨
            - CI/CD 파이프라인과의 통합을 통해 개발 및 배포 프로세스를 자동화할 수 있음
        - 비용 효율성
    - 사용 사례
        - 애플리케이션 개발 및 배포: 컨테이너화된 애플리케이션의 빌드, 저장 및 배포 과정을 간소화함
        - DevOps 및 CI/cd: 소스 코드 변경 시 자동으로 컨테이너 이미지를 빌드하고 ECR에 푸시하는 등의 워크플로우를 구성할 수 있음
        - 마이크로서비스 아키텍처: 마이크로서비스 각각을 독립된 컨테이너로 패키징하고 관리할 수 있어, 각 서비스의 개발, 배포 및 확장이 용이해짐